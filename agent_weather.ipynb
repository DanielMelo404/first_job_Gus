{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "898746f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69f8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys Set:\n",
      "Google API Key set: Yes\n",
      "OpenAI API Key set: No (REPLACE PLACEHOLDER!)\n",
      "Anthropic API Key set: No (REPLACE PLACEHOLDER!)\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTANT: Replace placeholders with your real API keys ---\n",
    "\n",
    "# Gemini API Key (Get from Google AI Studio: https://aistudio.google.com/app/apikey)\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAJGLkqBvCBAACD6Mb6HWfJFYZ6L6vti8M\" # <--- REPLACE\n",
    "\n",
    "# OpenAI API Key (Get from OpenAI Platform: https://platform.openai.com/api-keys)\n",
    "os.environ['OPENAI_API_KEY'] = 'YOUR_OPENAI_API_KEY' # <--- REPLACE\n",
    "\n",
    "# Anthropic API Key (Get from Anthropic Console: https://console.anthropic.com/settings/keys)\n",
    "os.environ['ANTHROPIC_API_KEY'] = 'YOUR_ANTHROPIC_API_KEY' # <--- REPLACE\n",
    "\n",
    "\n",
    "# --- Verify Keys (Optional Check) ---\n",
    "print(\"API Keys Set:\")\n",
    "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "print(f\"OpenAI API Key set: {'Yes' if os.environ.get('OPENAI_API_KEY') and os.environ['OPENAI_API_KEY'] != 'YOUR_OPENAI_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "print(f\"Anthropic API Key set: {'Yes' if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'YOUR_ANTHROPIC_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "\n",
    "# Configure ADK to use API keys directly (not Vertex AI for this multi-model setup)\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n",
    "\n",
    "\n",
    "# @markdown **Security Note:** It's best practice to manage API keys securely (e.g., using Colab Secrets or environment variables) rather than hardcoding them directly in the notebook. Replace the placeholder strings above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa057816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment configured.\n"
     ]
    }
   ],
   "source": [
    "MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash\"\n",
    "\n",
    "# Note: Specific model names might change. Refer to LiteLLM or the model provider's documentation.\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "MODEL_CLAUDE_SONNET = \"anthropic/claude-3-sonnet-20240229\"\n",
    "\n",
    "\n",
    "print(\"\\nEnvironment configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da1ff93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wheather(city:str)->dict:\n",
    "    \"\"\"\n",
    "    Tool that will return the weather information for the specified city.\n",
    "    Args:\n",
    "        city (str): The city for which we are requesting the weather information\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary whith the weather information or with the error for retrieving the weather information.\n",
    "        If error: Has a key 'status' with value 'error'. Has another key 'content' with the explanation of the error.\n",
    "        If successful: Has a key 'status' with value 'success'. Has another key 'content' with the information of the wheather information for the city.\n",
    "    \"\"\"\n",
    "    city = city.lower().replace(\"  \",\" \")\n",
    "\n",
    "    wheather_dict = {\n",
    "        \"amsterdam\": \"It's cloudy and raining\",\n",
    "        \"caracas\": \"It's very sunny but windy\",\n",
    "        \"paris\": \"It's super hot\"\n",
    "    }\n",
    "\n",
    "    if city in wheather_dict:\n",
    "        return {\"status\":\"successful\", \"content\":wheather_dict[city]}\n",
    "    else:\n",
    "        return {\"status\":\"error\", \"content\":\"The city is not supported\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7753e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'my_wheather_agent' created using model 'MODEL_GEMINI_2_5_PRO'.\n"
     ]
    }
   ],
   "source": [
    "AGENT_MODEL = \"MODEL_GEMINI_2_5_PRO\" # Starting with a powerful Gemini model\n",
    "\n",
    "my_wheather_agent = Agent(\n",
    "    name=\"my_wheather_agent\",\n",
    "    model=MODEL_GEMINI_2_0_FLASH,\n",
    "    description=\"You are an agent with purpose and function it's to keep what the weather is like in some specific cities\",\n",
    "    instruction=\"You're an agent that's gonna give the weather information for a city.you're very kind. You have a tool that is called get_weather. you're gonna call this function for requestingthe weather informationfor a city.You will analyze the response from this tool and if the output of this tool it's an error then you're gonna communicate the error that happenedIf the tool successfully gives you the information of the weather for the city then you're gonna communicate this to the user.Only use the tool when there's a request for the weather of some city.\",\n",
    "    tools= [get_wheather] # Add the get_weather function as a tool\n",
    ")\n",
    "print(f\"Agent '{my_agent.name}' created using model '{AGENT_MODEL}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b3a0428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_service = InMemorySessionService()\n",
    "\n",
    "APP_NAME='whather_daniels_app'\n",
    "USER_ID='daniel'\n",
    "SESSION_ID='session_1'\n",
    "\n",
    "session = session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "\n",
    "\n",
    "runner = Runner(\n",
    "    app_name=APP_NAME,\n",
    "    agent=my_wheather_agent,\n",
    "    session_service=session_service\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5957117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio \n",
    "\n",
    "async def interact_with_agent(query:str):\n",
    "    content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "    final_response_text = \"Agent did not produce a final response.\" # Default\n",
    "    async for event in runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content):\n",
    "        print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                final_response_text = event.content.parts[0].text\n",
    "            elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "                final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "                # Add more checks here if needed (e.g., specific error codes)\n",
    "                break # Stop processing events once the final response is found\n",
    "\n",
    "    print(f\"<<< Agent Response: {final_response_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9376caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Run the Initial Conversation\n",
    "\n",
    "# # We need an async function to await our interaction helper\n",
    "# async def run_conversation():\n",
    "#     await call_agent_async(\"What is the weather like in London?\",\n",
    "#                                        runner=runner,\n",
    "#                                        user_id=USER_ID,\n",
    "#                                        session_id=SESSION_ID)\n",
    "\n",
    "#     await call_agent_async(\"How about Paris?\",\n",
    "#                                        runner=runner,\n",
    "#                                        user_id=USER_ID,\n",
    "#                                        session_id=SESSION_ID) # Expecting the tool's error message\n",
    "\n",
    "#     await call_agent_async(\"Tell me the weather in New York\",\n",
    "#                                        runner=runner,\n",
    "#                                        user_id=USER_ID,\n",
    "#                                        session_id=SESSION_ID)\n",
    "\n",
    "# # Execute the conversation using await in an async context (like Colab/Jupyter)\n",
    "# await run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ce05cc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Event] Author: my_wheather_agent, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id='adk-1c8d2c6f-3082-4dee-995b-4e9cf06a7a88', args={'city': 'neiva'}, name='get_wheather'), function_response=None, inline_data=None, text=None)] role='model'\n",
      "  [Event] Author: my_wheather_agent, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id='adk-1c8d2c6f-3082-4dee-995b-4e9cf06a7a88', name='get_wheather', response={'status': 'error', 'content': 'The city is not supported'}), inline_data=None, text=None)] role='user'\n",
      "  [Event] Author: my_wheather_agent, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I am sorry, the city is not supported\\n')] role='model'\n",
      "<<< Agent Response: I am sorry, the city is not supported\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def run_conversation():\n",
    "    await interact_with_agent(\"como esta el clima en neiva\")\n",
    "\n",
    "\n",
    "await run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54fb2e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Event] Author: my_wheather_agent, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='The last city I mentioned was Neiva.\\n')] role='model'\n",
      "<<< Agent Response: The last city I mentioned was Neiva.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await interact_with_agent(\"what was the las city you mentioned?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67168948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "def drag_scrollbar(start_pos, pixels, steps=30, delay=0.01):\n",
    "    \"\"\"\n",
    "    Clicks and drags the scrollbar from start_pos by a given number of pixels.\n",
    "\n",
    "    Args:\n",
    "        start_pos (tuple): (x, y) position to click the scrollbar.\n",
    "        pixels (int): Number of pixels to drag. Positive = down, Negative = up.\n",
    "        steps (int): Number of steps to make the drag smooth.\n",
    "        delay (float): Delay between each step.\n",
    "    \"\"\"\n",
    "    pyautogui.moveTo(*start_pos)\n",
    "    pyautogui.mouseDown()\n",
    "\n",
    "    pyautogui.moveRel(0, pixels)\n",
    "    # step_size = pixels / steps\n",
    "    # for _ in range(steps):\n",
    "    #     pyautogui.moveRel(0, step_size)\n",
    "    #     time.sleep(delay)\n",
    "\n",
    "    pyautogui.mouseUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9431185",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "drag_scrollbar((1904,127),230)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
